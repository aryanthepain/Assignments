{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment 1 DA221\n",
    "\n",
    "- Name- Aryan Gupta\n",
    "- Roll Number- 230150003\n",
    "- Date- 27/1/25 \n",
    "- Start Time- 15:42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing math library\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "## Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights\n",
    "wh11 = 0.1\n",
    "wh12 = 0.3\n",
    "wh21 = 0.3\n",
    "wh22 = 0.4\n",
    "wo11 = 0.4\n",
    "wo12 = 0.6\n",
    "\n",
    "# input and output\n",
    "x1=0.2\n",
    "x2=0.6\n",
    "t1=0.7\n",
    "\n",
    "# learning rate\n",
    "alpha=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The activations of hidden neurons are:-\n",
      "h1:  0.549833997312478\n",
      "h2:  0.574442516811659\n",
      "\n",
      "==============\n",
      "\n",
      "The activations of output neuron is:-\n",
      "y1:  0.6375160160941549\n",
      "\n",
      "==============\n",
      "\n",
      "The Loss is  0.003904248244745908 .\n"
     ]
    }
   ],
   "source": [
    "# hidden nuerons\n",
    "v1=wh11*x1+wh12*x2\n",
    "v2=wh21*x1+wh22*x2\n",
    "\n",
    "h1=1/(1+math.exp(-v1))\n",
    "h2=1/(1+math.exp(-v2))\n",
    "\n",
    "# printing\n",
    "print(\"The activations of hidden neurons are:-\")\n",
    "print(\"h1: \", h1)\n",
    "print(\"h2: \", h2)\n",
    "\n",
    "print(\"\\n==============\\n\")\n",
    "\n",
    "# Output neuron\n",
    "z1=wo11*h1+wo12*h2\n",
    "y1=1/(1+math.exp(-z1))\n",
    "print(\"The activations of output neuron is:-\")\n",
    "print(\"y1: \", y1)\n",
    "\n",
    "print(\"\\n==============\\n\")\n",
    "\n",
    "# Loss Function\n",
    "L = (t1-y1)**2\n",
    "print(\"The Loss is \",L,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propogation\n",
    "### Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output gradients:-\n",
      "Gradient of w011:  -0.007939263637127044\n",
      "Gradient of w012:  -0.008294595473605585\n",
      "\n",
      "==============\n",
      "\n",
      "Hidden Gradients:-\n",
      "Gradient of wh11:  -0.00018482410155054986\n",
      "Gradient of wh12:  -0.0005544723046516495\n",
      "Gradient of wh21:  -0.00036387244992764495\n",
      "Gradient of wh22:  -0.0010916173497829346\n"
     ]
    }
   ],
   "source": [
    "# Output gradients\n",
    "grad_wo11 = (y1-t1)*y1*(1-y1)*h1\n",
    "grad_wo12 = (y1-t1)*y1*(1-y1)*h2\n",
    "print(\"Output gradients:-\")\n",
    "print(\"Gradient of w011: \", grad_wo11)\n",
    "print(\"Gradient of w012: \", grad_wo12)\n",
    "\n",
    "print(\"\\n==============\\n\")\n",
    "\n",
    "# Hidden gradients\n",
    "grad_wh11=(y1-t1)*y1*(1-y1)*wo11*v1*(1-v1)*x1\n",
    "grad_wh12=(y1-t1)*y1*(1-y1)*wo11*v1*(1-v1)*x2\n",
    "grad_wh21=(y1-t1)*y1*(1-y1)*wo12*v2*(1-v2)*x1\n",
    "grad_wh22=(y1-t1)*y1*(1-y1)*wo12*v2*(1-v2)*x2\n",
    "print(\"Hidden Gradients:-\")\n",
    "print(\"Gradient of wh11: \", grad_wh11)\n",
    "print(\"Gradient of wh12: \", grad_wh12)\n",
    "print(\"Gradient of wh21: \", grad_wh21)\n",
    "print(\"Gradient of wh22: \", grad_wh22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New hidden weights:-\n",
      "wh11:  0.0996303517968989\n",
      "wh12:  0.2988910553906967\n",
      "wh21:  0.2992722551001447\n",
      "wh22:  0.39781676530043414\n",
      "\n",
      "==============\n",
      "\n",
      "New Output Weights:-\n",
      "w011:  0.3841214727257459\n",
      "w012:  0.5834108090527889\n"
     ]
    }
   ],
   "source": [
    "# hidden neurons\n",
    "wh11=wh11+alpha*grad_wh11\n",
    "wh12=wh12+alpha*grad_wh12\n",
    "wh21=wh21+alpha*grad_wh21\n",
    "wh22=wh22+alpha*grad_wh22\n",
    "\n",
    "print(\"New hidden weights:-\")\n",
    "print(\"wh11: \", wh11)\n",
    "print(\"wh12: \", wh12)\n",
    "print(\"wh21: \", wh21)\n",
    "print(\"wh22: \", wh22)\n",
    "\n",
    "print(\"\\n==============\\n\")\n",
    "\n",
    "# Output neuron\n",
    "wo11=wo11+alpha*grad_wo11\n",
    "wo12=wo12+alpha*grad_wo12\n",
    "\n",
    "print(\"New Output Weights:-\")\n",
    "print(\"w011: \", wo11)\n",
    "print(\"w012: \", wo12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
