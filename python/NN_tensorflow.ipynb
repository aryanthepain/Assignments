{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2p37fE9Fc02"
      },
      "source": [
        "# Generating the sample data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[1.  0.5]\n",
            " [0.9 0.7]\n",
            " [0.4 0.6]\n",
            " [0.3 0.4]\n",
            " [1.1 0.8]\n",
            " [0.6 0.9]], shape=(6, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [1. 1.]\n",
            " [0. 0.]], shape=(6, 2), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Sample dataset (X: input, y: labels)\n",
        "X = tf.constant([[1.0, 0.5],\n",
        "                 [0.9, 0.7],\n",
        "                 [0.4, 0.6],\n",
        "                 [0.3, 0.4],\n",
        "                 [1.1, 0.8],\n",
        "                 [0.6, 0.9]], dtype=tf.float32)\n",
        "\n",
        "y = tf.constant([[1, 1], [1, 0], [0, 1], [0, 0], [1, 1], [0, 0]], dtype=tf.float32)\n",
        "\n",
        "print(type(X), type(y))\n",
        "print(X)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho4gkN7hlIn3"
      },
      "source": [
        "# Standardization + Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "[[1.  0.5]\n",
            " [0.9 0.7]\n",
            " [0.4 0.6]\n",
            " [0.3 0.4]\n",
            " [1.1 0.8]\n",
            " [0.6 0.9]]\n",
            "\n",
            " <class 'numpy.ndarray'>\n",
            "[[ 0.93724036 -0.87831014]\n",
            " [ 0.60644954  0.29276994]\n",
            " [-1.047504   -0.2927699 ]\n",
            " [-1.3782946  -1.4638501 ]\n",
            " [ 1.2680311   0.87831014]\n",
            " [-0.38592246  1.46385   ]]\n",
            "\n",
            " <class 'numpy.ndarray'>\n",
            "[[0.875      0.20000002]\n",
            " [0.74999994 0.6       ]\n",
            " [0.12499994 0.4000001 ]\n",
            " [0.         0.        ]\n",
            " [1.         0.8000001 ]\n",
            " [0.375      1.        ]]\n",
            "\n",
            " <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "[[0.875      0.20000002]\n",
            " [0.74999994 0.6       ]\n",
            " [0.12499994 0.4000001 ]\n",
            " [0.         0.        ]\n",
            " [1.         0.8000001 ]\n",
            " [0.375      1.        ]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Sample dataset (X: input)\n",
        "X = tf.constant([[1.0, 0.5],\n",
        "                 [0.9, 0.7],\n",
        "                 [0.4, 0.6],\n",
        "                 [0.3, 0.4],\n",
        "                 [1.1, 0.8],\n",
        "                 [0.6, 0.9]], dtype=tf.float32)\n",
        "\n",
        "print('\\n', type(X))\n",
        "print(X.numpy())\n",
        "\n",
        "# Z-score Scaling (Standardization) data to have mean = 0 and std = 1\n",
        "standard_scaler = StandardScaler()\n",
        "data_standardized = standard_scaler.fit_transform(X.numpy())\n",
        "print('\\n', type(data_standardized))\n",
        "print(data_standardized)\n",
        "\n",
        "# Min-Max Scaling (Normalization) - values scaled to a specific range\n",
        "min_max_scaler = MinMaxScaler()\n",
        "data_normalized = min_max_scaler.fit_transform(data_standardized)\n",
        "print('\\n', type(data_normalized))\n",
        "print(data_normalized)\n",
        "\n",
        "# Convert back to TensorFlow tensor\n",
        "X = tf.convert_to_tensor(data_normalized, dtype=tf.float32)\n",
        "print('\\n', type(X))\n",
        "print(X.numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l788XGfLlQo9"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model created successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Gautam Takhellambam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define a simple neural network\n",
        "class SimpleNN(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = layers.Dense(3, input_shape=(2,), activation=None)  # First layer (2 inputs, 3 neurons)\n",
        "        self.act1 = layers.ReLU()\n",
        "        self.fc2 = layers.Dense(2, activation=None)  # Output layer (3 inputs, 2 outputs)\n",
        "        self.act2 = layers.Activation('sigmoid')\n",
        "\n",
        "    def call(self, x):\n",
        "        # Print model parameters\n",
        "        initial_params = {v.name: v.numpy() for v in self.trainable_variables}\n",
        "        for name, param in initial_params.items():\n",
        "            print(f\"\\nParameters of {name}: \\n{param}\\n\")\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        print(f\"\\nActivation after first hidden layer: \\n{x.numpy()}\")  # Print activations of the first layer\n",
        "        x = self.act1(x)\n",
        "        print(f\"\\nNon-linearity after first ReLU layer: \\n{x.numpy()}\")  # Print non-linearity of the first layer\n",
        "        x = self.fc2(x)\n",
        "        print(f\"\\nActivation after second output layer: \\n{x.numpy()}\")  # Print activations of the second layer\n",
        "        x = self.act2(x)\n",
        "        print(f\"\\nOutput after second output layer (sigmoid): \\n{x.numpy()}\")  # Print output of the model\n",
        "        return x\n",
        "\n",
        "# Instantiate model\n",
        "model = SimpleNN()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "print(\"Model created successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq4BpJxrn5np"
      },
      "source": [
        "# Training & evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[-0.23330271  0.05059576  0.6155164 ]\n",
            " [ 1.0137458   0.37962914  0.85187435]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[0. 0. 0.]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[-0.0013907   0.12019712  0.7089517 ]\n",
            " [ 0.4332705   0.2657243   0.97276187]\n",
            " [ 0.3763356   0.15817615  0.41768935]\n",
            " [ 0.          0.          0.        ]\n",
            " [ 0.577694    0.3542991   1.2970159 ]\n",
            " [ 0.92625725  0.39860255  1.082693  ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.         0.12019712 0.7089517 ]\n",
            " [0.4332705  0.2657243  0.97276187]\n",
            " [0.3763356  0.15817615 0.41768935]\n",
            " [0.         0.         0.        ]\n",
            " [0.577694   0.3542991  1.2970159 ]\n",
            " [0.92625725 0.39860255 1.082693  ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.3517997   0.10913294]\n",
            " [-0.28386524  0.14344586]\n",
            " [-0.03459071  0.05872421]\n",
            " [ 0.          0.        ]\n",
            " [-0.37848705  0.19126116]\n",
            " [-0.11225232  0.15296157]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.412946   0.5272562 ]\n",
            " [0.4295064  0.53580004]\n",
            " [0.49135318 0.5146768 ]\n",
            " [0.5        0.5       ]\n",
            " [0.40649185 0.54767007]\n",
            " [0.47196636 0.538166  ]]\n",
            "\n",
            "Epoch [1/10], Loss: 0.7314162850379944\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.02810607 -0.03492265  0.05539658]\n",
            " [-0.00864653  0.00508931  0.01281943]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.00851141 -0.0274556   0.0329137 ]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00266932  0.02388949]\n",
            " [-0.01388236  0.00525336]\n",
            " [-0.08539244 -0.00172263]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02397801  0.01363076]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.23330271  0.05059576  0.6155164 ]\n",
            " [ 1.0137458   0.37962914  0.85187435]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[0. 0. 0.]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.41469073 -0.13876802]\n",
            " [ 0.19018233  0.53399885]\n",
            " [-0.5284691   0.06340039]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[0. 0.]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.23230283  0.05159566  0.6145165 ]\n",
            " [ 1.0147454   0.37862977  0.8508746 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00099962  0.00099988 -0.0009999 ]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.4136919  -0.13976789]\n",
            " [ 0.19118209  0.53299946]\n",
            " [-0.52746916  0.06439855]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00099986 -0.00099976]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.4136919  -0.13976789]\n",
            " [ 0.19118209  0.53299946]\n",
            " [-0.52746916  0.06439855]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00099986 -0.00099976]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 6.83732214e-04  1.21872045e-01  7.06877053e-01]\n",
            " [ 4.35619771e-01  2.66874492e-01  9.70412314e-01]\n",
            " [ 3.77860039e-01  1.58901289e-01  4.16164547e-01]\n",
            " [ 9.99621931e-04  9.99878161e-04 -9.99897253e-04]\n",
            " [ 5.80493152e-01  3.55499387e-01  1.29421639e+00]\n",
            " [ 9.28631425e-01  3.98978025e-01  1.08031833e+00]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[6.83732214e-04 1.21872045e-01 7.06877053e-01]\n",
            " [4.35619771e-01 2.66874492e-01 9.70412314e-01]\n",
            " [3.77860039e-01 1.58901289e-01 4.16164547e-01]\n",
            " [9.99621931e-04 9.99878161e-04 0.00000000e+00]\n",
            " [5.80493152e-01 3.55499387e-01 1.29421639e+00]\n",
            " [9.28631425e-01 3.98978025e-01 1.08031833e+00]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.34827337  0.10938426]\n",
            " [-0.2796287   0.1428517 ]\n",
            " [-0.03181738  0.05768224]\n",
            " [ 0.00160456 -0.00060654]\n",
            " [-0.37354892  0.19069257]\n",
            " [-0.10838999  0.15143338]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.4138011  0.5273188 ]\n",
            " [0.43054476 0.5356523 ]\n",
            " [0.4920463  0.5144166 ]\n",
            " [0.50040114 0.49984837]\n",
            " [0.40768376 0.5475292 ]\n",
            " [0.472929   0.5377862 ]]\n",
            "\n",
            "Epoch [2/10], Loss: 0.7310647368431091\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.04082553 -0.03496984  0.05512048]\n",
            " [-0.01149505  0.00506745  0.01267973]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01163552  0.00271775  0.03260702]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00277495  0.02389863]\n",
            " [-0.01388391  0.00519975]\n",
            " [-0.084823   -0.00175178]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02354949  0.01354596]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.23230283  0.05159566  0.6145165 ]\n",
            " [ 1.0147454   0.37862977  0.8508746 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00099962  0.00099988 -0.0009999 ]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.4136919  -0.13976789]\n",
            " [ 0.19118209  0.53299946]\n",
            " [-0.52746916  0.06439855]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00099986 -0.00099976]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.23131004  0.05259562  0.6135167 ]\n",
            " [ 1.0157425   0.37763035  0.8498751 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00199557  0.00159326 -0.00199956]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.41269192 -0.1407678 ]\n",
            " [ 0.19218193  0.5320002 ]\n",
            " [-0.52646935  0.06539766]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00199925 -0.00199942]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.41269192 -0.1407678 ]\n",
            " [ 0.19218193  0.5320002 ]\n",
            " [-0.52646935  0.06539766]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00199925 -0.00199942]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.00274781  0.12314051  0.7048026 ]\n",
            " [ 0.4379586   0.2676182   0.968063  ]\n",
            " [ 0.37937894  0.15921989  0.4146401 ]\n",
            " [ 0.00199557  0.00159326 -0.00199956]\n",
            " [ 0.5832796   0.3562932   1.2914171 ]\n",
            " [ 0.93099684  0.39894697  1.0779443 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.00274781 0.12314051 0.7048026 ]\n",
            " [0.4379586  0.2676182  0.968063  ]\n",
            " [0.37937894 0.15921989 0.4146401 ]\n",
            " [0.00199557 0.00159326 0.        ]\n",
            " [0.5832796  0.3562932  1.2914171 ]\n",
            " [0.93099684 0.39894697 1.0779443 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.3442583   0.10921699]\n",
            " [-0.27548286  0.1420321 ]\n",
            " [-0.02913025  0.05641774]\n",
            " [ 0.003129   -0.00143272]\n",
            " [-0.36870438  0.1898973 ]\n",
            " [-0.10462009  0.14968109]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41477543 0.5272771 ]\n",
            " [0.4315615  0.5354484 ]\n",
            " [0.49271795 0.5141007 ]\n",
            " [0.50078225 0.49964184]\n",
            " [0.4088541  0.54733217]\n",
            " [0.4738688  0.53735054]]\n",
            "\n",
            "Epoch [3/10], Loss: 0.7306941151618958\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.04057309 -0.03502522  0.05484124]\n",
            " [-0.01137908  0.00503772  0.01254113]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01143184  0.00270111  0.0322978 ]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00281105  0.02384185]\n",
            " [-0.01387614  0.00513396]\n",
            " [-0.08425526 -0.00180424]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02311999  0.01342923]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.23131004  0.05259562  0.6135167 ]\n",
            " [ 1.0157425   0.37763035  0.8498751 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00199557  0.00159326 -0.00199956]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.41269192 -0.1407678 ]\n",
            " [ 0.19218193  0.5320002 ]\n",
            " [-0.52646935  0.06539766]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00199925 -0.00199942]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.23031157  0.05359567  0.61251706]\n",
            " [ 1.0167434   0.37663108  0.84887606]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00299569  0.00198747 -0.00299882]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.41169107 -0.14176765]\n",
            " [ 0.19318178  0.5310014 ]\n",
            " [-0.52546984  0.06639805]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00299779 -0.00299874]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.41169107 -0.14176765]\n",
            " [ 0.19318178  0.5310014 ]\n",
            " [-0.52546984  0.06639805]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00299779 -0.00299874]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.00482177  0.12420991  0.70272887]\n",
            " [ 0.44030812  0.26816288  0.9657146 ]\n",
            " [ 0.38090423  0.1593394   0.41311628]\n",
            " [ 0.00299569  0.00198747 -0.00299882]\n",
            " [ 0.5860789   0.35688803  1.2886192 ]\n",
            " [ 0.93337226  0.39871693  1.0755711 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.00482177 0.12420991 0.70272887]\n",
            " [0.44030812 0.26816288 0.9657146 ]\n",
            " [0.38090423 0.1593394  0.41311628]\n",
            " [0.00299569 0.00198747 0.        ]\n",
            " [0.5860789  0.35688803 1.2886192 ]\n",
            " [0.93337226 0.39871693 1.0755711 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.34028485  0.10893314]\n",
            " [-0.271381    0.14109623]\n",
            " [-0.02648602  0.05504091]\n",
            " [ 0.00461503 -0.00236809]\n",
            " [-0.36390498  0.18898407]\n",
            " [-0.1008965   0.14781432]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41574025 0.52720636]\n",
            " [0.43256804 0.5352156 ]\n",
            " [0.49337888 0.5137567 ]\n",
            " [0.5011537  0.499408  ]\n",
            " [0.4100146  0.54710597]\n",
            " [0.47479725 0.53688645]]\n",
            "\n",
            "Epoch [4/10], Loss: 0.7303252220153809\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.040321   -0.03508447  0.0545633 ]\n",
            " [-0.01126351  0.00500431  0.01240381]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01122884  0.00267703  0.03199062]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00284616  0.02377895]\n",
            " [-0.01386445  0.00506229]\n",
            " [-0.08369325 -0.00186697]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.0226956   0.01329827]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.23031157  0.05359567  0.61251706]\n",
            " [ 1.0167434   0.37663108  0.84887606]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00299569  0.00198747 -0.00299882]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.41169107 -0.14176765]\n",
            " [ 0.19318178  0.5310014 ]\n",
            " [-0.52546984  0.06639805]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00299779 -0.00299874]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22930981  0.05459581  0.6115178 ]\n",
            " [ 1.0177461   0.37563217  0.8478777 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00399771  0.00225294 -0.00399747]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.41068932 -0.14276735]\n",
            " [ 0.1941816   0.5300034 ]\n",
            " [-0.52447075  0.06740023]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00399512 -0.00399749]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.41068932 -0.14276735]\n",
            " [ 0.1941816   0.5300034 ]\n",
            " [-0.52447075  0.06740023]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00399512 -0.00399749]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.00690086  0.12515071  0.7006562 ]\n",
            " [ 0.44266304  0.2685791   0.9633675 ]\n",
            " [ 0.38243252  0.15933032  0.41159335]\n",
            " [ 0.00399771  0.00225294 -0.00399747]\n",
            " [ 0.58888483  0.35735452  1.2858225 ]\n",
            " [ 0.9357526   0.39835852  1.0731994 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.00690086 0.12515071 0.7006562 ]\n",
            " [0.44266304 0.2685791  0.9633675 ]\n",
            " [0.38243252 0.15933032 0.41159335]\n",
            " [0.00399771 0.00225294 0.        ]\n",
            " [0.58888483 0.35735452 1.2858225 ]\n",
            " [0.9357526  0.39835852 1.0731994 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.33634248  0.10857198]\n",
            " [-0.26731285  0.14008372]\n",
            " [-0.02387359  0.05359073]\n",
            " [ 0.00607442 -0.00337417]\n",
            " [-0.35914078  0.18799284]\n",
            " [-0.09720907  0.14587286]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41669816 0.52711636]\n",
            " [0.43356687 0.5349637 ]\n",
            " [0.4940319  0.51339453]\n",
            " [0.5015186  0.49915645]\n",
            " [0.41116756 0.54686034]\n",
            " [0.47571686 0.53640366]]\n",
            "\n",
            "Epoch [5/10], Loss: 0.7299583554267883\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.04006934 -0.03514614  0.05428647]\n",
            " [-0.0111484   0.00496866  0.01226759]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01102663  0.00264835  0.03168515]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00288111  0.02371176]\n",
            " [-0.01385039  0.00498678]\n",
            " [-0.083136   -0.00193624]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02227501  0.01315793]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.22930981  0.05459581  0.6115178 ]\n",
            " [ 1.0177461   0.37563217  0.8478777 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00399771  0.00225294 -0.00399747]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.41068932 -0.14276735]\n",
            " [ 0.1941816   0.5300034 ]\n",
            " [-0.52447075  0.06740023]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00399512 -0.00399749]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22830623  0.05559609  0.6105189 ]\n",
            " [ 1.0187496   0.37463376  0.8468802 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00500017  0.00242458 -0.00499535]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.40968657 -0.14376687]\n",
            " [ 0.19518137  0.5290066 ]\n",
            " [-0.5234722   0.06840478]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00499089 -0.00499544]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.40968657 -0.14376687]\n",
            " [ 0.19518137  0.5290066 ]\n",
            " [-0.5234722   0.06840478]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00499089 -0.00499544]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.00898216  0.12599793  0.69858474]\n",
            " [ 0.44502032  0.2689019   0.9610219 ]\n",
            " [ 0.38396186  0.15922764  0.4100716 ]\n",
            " [ 0.00500017  0.00242458 -0.00499535]\n",
            " [ 0.5916937   0.3577277   1.2830278 ]\n",
            " [ 0.9381349   0.3979069   1.0708294 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.00898216 0.12599793 0.69858474]\n",
            " [0.44502032 0.2689019  0.9610219 ]\n",
            " [0.38396186 0.15922764 0.4100716 ]\n",
            " [0.00500017 0.00242458 0.        ]\n",
            " [0.5916937  0.3577277  1.2830278 ]\n",
            " [0.9381349  0.3979069  1.0708294 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.3324265   0.10815349]\n",
            " [-0.26327386  0.13901475]\n",
            " [-0.02128791  0.05208689]\n",
            " [ 0.00751262 -0.00443168]\n",
            " [-0.35440776  0.18694417]\n",
            " [-0.09355323  0.14387707]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41765025 0.52701205]\n",
            " [0.43455905 0.5346978 ]\n",
            " [0.4946782  0.5130188 ]\n",
            " [0.50187814 0.49889207]\n",
            " [0.41231394 0.5466004 ]\n",
            " [0.47662872 0.5359073 ]]\n",
            "\n",
            "Epoch [6/10], Loss: 0.7295936942100525\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.03981814 -0.03520945  0.05401067]\n",
            " [-0.01103378  0.0049315   0.01213241]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01082528  0.00261655  0.03138124]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.0029163   0.02364125]\n",
            " [-0.01383478  0.00490851]\n",
            " [-0.08258314 -0.00201017]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02185762  0.01301071]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.22830623  0.05559609  0.6105189 ]\n",
            " [ 1.0187496   0.37463376  0.8468802 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00500017  0.00242458 -0.00499535]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.40968657 -0.14376687]\n",
            " [ 0.19518137  0.5290066 ]\n",
            " [-0.5234722   0.06840478]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00499089 -0.00499544]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22730173  0.05659655  0.6095205 ]\n",
            " [ 1.0197531   0.373636    0.8458838 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00600208  0.00252314 -0.00599229]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.40868264 -0.1447661 ]\n",
            " [ 0.19618104  0.52801126]\n",
            " [-0.5224743   0.06941225]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00598473 -0.00599235]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.40868264 -0.1447661 ]\n",
            " [ 0.19618104  0.52801126]\n",
            " [-0.5224743   0.06941225]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00598473 -0.00599235]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.01106371  0.12677233  0.6965149 ]\n",
            " [ 0.44737765  0.26915216  0.9586783 ]\n",
            " [ 0.38549072  0.15905215  0.40855134]\n",
            " [ 0.00600208  0.00252314 -0.00599229]\n",
            " [ 0.5945029   0.35802853  1.2802353 ]\n",
            " [ 0.940517    0.39738286  1.0684617 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.01106371 0.12677233 0.6965149 ]\n",
            " [0.44737765 0.26915216 0.9586783 ]\n",
            " [0.38549072 0.15905215 0.40855134]\n",
            " [0.00600208 0.00252314 0.        ]\n",
            " [0.5945029  0.35802853 1.2802353 ]\n",
            " [0.940517   0.39738286 1.0684617 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.32853454  0.10768989]\n",
            " [-0.25926203  0.13790192]\n",
            " [-0.01872646  0.05054146]\n",
            " [ 0.00893267 -0.005529  ]\n",
            " [-0.34970388  0.18585087]\n",
            " [-0.08992706  0.14183962]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41859716 0.5268964 ]\n",
            " [0.43554506 0.53442097]\n",
            " [0.49531853 0.5126326 ]\n",
            " [0.50223315 0.49861774]\n",
            " [0.41345423 0.54632944]\n",
            " [0.47753334 0.53540057]]\n",
            "\n",
            "Epoch [7/10], Loss: 0.7292313575744629\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.03956745 -0.03527396  0.05373588]\n",
            " [-0.01091972  0.00489328  0.01199825]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01062489  0.00258251  0.03107885]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00295194  0.02356798]\n",
            " [-0.01381816  0.00482812]\n",
            " [-0.08203449 -0.00208754]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02144321  0.01285816]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.22730173  0.05659655  0.6095205 ]\n",
            " [ 1.0197531   0.373636    0.8458838 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00600208  0.00252314 -0.00599229]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.40868264 -0.1447661 ]\n",
            " [ 0.19618104  0.52801126]\n",
            " [-0.5224743   0.06941225]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00598473 -0.00599235]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.2262969   0.0575972   0.60852265]\n",
            " [ 1.0207561   0.37263912  0.8448887 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00700268  0.00256237 -0.00698811]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.4076774  -0.14576502]\n",
            " [ 0.1971806   0.5270178 ]\n",
            " [-0.52147716  0.07042319]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00697629 -0.00698795]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.4076774  -0.14576502]\n",
            " [ 0.1971806   0.5270178 ]\n",
            " [-0.52147716  0.07042319]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.00697629 -0.00698795]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.01314413  0.12748775  0.694447  ]\n",
            " [ 0.4497337   0.26934373  0.95633703]\n",
            " [ 0.3870181   0.15881771  0.40703276]\n",
            " [ 0.00700268  0.00256237 -0.00698811]\n",
            " [ 0.5973107   0.35827088  1.2774456 ]\n",
            " [ 0.94289744  0.39680043  1.0660965 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.01314413 0.12748775 0.694447  ]\n",
            " [0.4497337  0.26934373 0.95633703]\n",
            " [0.3870181  0.15881771 0.40703276]\n",
            " [0.00700268 0.00256237 0.        ]\n",
            " [0.5973107  0.35827088 1.2774456 ]\n",
            " [0.94289744 0.39680043 1.0660965 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.32466525  0.10718957]\n",
            " [-0.25527602  0.13675383]\n",
            " [-0.01618768  0.04896264]\n",
            " [ 0.01033637 -0.00665829]\n",
            " [-0.34502822  0.18472193]\n",
            " [-0.08632938  0.13976938]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.41953915 0.5267718 ]\n",
            " [0.4365253  0.5341352 ]\n",
            " [0.49595317 0.51223814]\n",
            " [0.5025841  0.49833542]\n",
            " [0.41458857 0.5460496 ]\n",
            " [0.47843105 0.5348855 ]]\n",
            "\n",
            "Epoch [8/10], Loss: 0.7288715243339539\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.03931729 -0.03533936  0.05346207]\n",
            " [-0.01080624  0.00485433  0.01186511]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.0104255   0.00254681  0.03077793]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00298816  0.02349237]\n",
            " [-0.01380086  0.00474605]\n",
            " [-0.08148995 -0.00216757]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02103155  0.01270133]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.2262969   0.0575972   0.60852265]\n",
            " [ 1.0207561   0.37263912  0.8448887 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00700268  0.00256237 -0.00698811]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.4076774  -0.14576502]\n",
            " [ 0.1971806   0.5270178 ]\n",
            " [-0.52147716  0.07042319]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00697629 -0.00698795]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22529215  0.05859808  0.6075255 ]\n",
            " [ 1.0217583   0.37164322  0.8438951 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00800135  0.0025521  -0.00798264]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.40667066 -0.14676355]\n",
            " [ 0.19818002  0.52602655]\n",
            " [-0.52048093  0.07143809]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.0079652  -0.00798201]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.40667066 -0.14676355]\n",
            " [ 0.19818002  0.52602655]\n",
            " [-0.52048093  0.07143809]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.0079652  -0.00798201]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.01522241  0.12815408  0.69238126]\n",
            " [ 0.45208725  0.26948658  0.95399857]\n",
            " [ 0.38854328  0.15853418  0.40551612]\n",
            " [ 0.00800135  0.0025521  -0.00798264]\n",
            " [ 0.6001159   0.35846475  1.274659  ]\n",
            " [ 0.94527507  0.3961696   1.0637345 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.01522241 0.12815408 0.69238126]\n",
            " [0.45208725 0.26948658 0.95399857]\n",
            " [0.38854328 0.15853418 0.40551612]\n",
            " [0.00800135 0.0025521  0.        ]\n",
            " [0.6001159  0.35846475 1.274659  ]\n",
            " [0.94527507 0.3961696  1.0637345 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.32081795  0.10665874]\n",
            " [-0.2513154   0.135577  ]\n",
            " [-0.01367074  0.04735648]\n",
            " [ 0.01172489 -0.00781384]\n",
            " [-0.34038043  0.18356404]\n",
            " [-0.08275981  0.13767296]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.42047638 0.5266394 ]\n",
            " [0.4374997  0.53384244]\n",
            " [0.4965824  0.5118369 ]\n",
            " [0.5029312  0.49804658]\n",
            " [0.41571707 0.5457626 ]\n",
            " [0.47932184 0.534364  ]]\n",
            "\n",
            "Epoch [9/10], Loss: 0.7285142540931702\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.03906768 -0.03540541  0.05318926]\n",
            " [-0.01069337  0.00481483  0.011733  ]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01022718  0.00250991  0.03047846]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.00302504  0.02341468]\n",
            " [-0.01378316  0.00466262]\n",
            " [-0.0809495  -0.00224961]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02062261  0.01254101]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.22529215  0.05859808  0.6075255 ]\n",
            " [ 1.0217583   0.37164322  0.8438951 ]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00800135  0.0025521  -0.00798264]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.40667066 -0.14676355]\n",
            " [ 0.19818002  0.52602655]\n",
            " [-0.52048093  0.07143809]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.0079652  -0.00798201]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22428781  0.05959923  0.6065291 ]\n",
            " [ 1.0227592   0.37064847  0.84290314]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00899756  0.00249973 -0.00897571]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.40566224 -0.14776161]\n",
            " [ 0.19917926  0.5250379 ]\n",
            " [-0.51948565  0.07245744]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.0089511  -0.00897425]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "\n",
            "Parameters of kernel: \n",
            "[[ 0.40566224 -0.14776161]\n",
            " [ 0.19917926  0.5250379 ]\n",
            " [-0.51948565  0.07245744]]\n",
            "\n",
            "\n",
            "Parameters of bias: \n",
            "[ 0.0089511  -0.00897425]\n",
            "\n",
            "\n",
            "Activation after first hidden layer: \n",
            "[[ 0.01729758  0.12877876  0.6903179 ]\n",
            " [ 0.4544373   0.26958823  0.951663  ]\n",
            " [ 0.39006537  0.15820906  0.4040017 ]\n",
            " [ 0.00899756  0.00249973 -0.00897571]\n",
            " [ 0.6029172   0.35861775  1.2718759 ]\n",
            " [ 0.9476488   0.39549792  1.0613759 ]]\n",
            "\n",
            "Non-linearity after first ReLU layer: \n",
            "[[0.01729758 0.12877876 0.6903179 ]\n",
            " [0.4544373  0.26958823 0.951663  ]\n",
            " [0.39006537 0.15820906 0.4040017 ]\n",
            " [0.00899756 0.00249973 0.        ]\n",
            " [0.6029172  0.35861775 1.2718759 ]\n",
            " [0.9476488  0.39549792 1.0613759 ]]\n",
            "\n",
            "Activation after second output layer: \n",
            "[[-0.31699213  0.10610223]\n",
            " [-0.24737975  0.13437647]\n",
            " [-0.01117524  0.04572774]\n",
            " [ 0.01309896 -0.00899129]\n",
            " [-0.3357602   0.1823825 ]\n",
            " [-0.0792181   0.1355556 ]]\n",
            "\n",
            "Output after second output layer (sigmoid): \n",
            "[[0.42140892 0.52650064]\n",
            " [0.4384685  0.53354365]\n",
            " [0.4972062  0.51142997]\n",
            " [0.5032747  0.4977522 ]\n",
            " [0.41683975 0.54546964]\n",
            " [0.48020583 0.5338371 ]]\n",
            "\n",
            "Epoch [10/10], Loss: 0.7281596064567566\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[-0.03881864 -0.03547198  0.05291742]\n",
            " [-0.01058114  0.004775    0.01160195]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.01002997  0.00247212  0.03018047]\n",
            "\n",
            "Gradient of kernel after backward pass: \n",
            "[[ 0.0030626   0.02333516]\n",
            " [-0.01376526  0.00457811]\n",
            " [-0.08041308 -0.00233323]]\n",
            "\n",
            "Gradient of bias after backward pass: \n",
            "[-0.02021634  0.01237778]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[-0.22428781  0.05959923  0.6065291 ]\n",
            " [ 1.0227592   0.37064847  0.84290314]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.00899756  0.00249973 -0.00897571]\n",
            "\n",
            "Weights of kernel before update: \n",
            "[[ 0.40566224 -0.14776161]\n",
            " [ 0.19917926  0.5250379 ]\n",
            " [-0.51948565  0.07245744]]\n",
            "\n",
            "Weights of bias before update: \n",
            "[ 0.0089511  -0.00897425]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[-0.22328413  0.06060067  0.60553354]\n",
            " [ 1.0237586   0.36965504  0.8419131 ]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00999082  0.00241104 -0.00996715]\n",
            "\n",
            "Weights of kernel after update: \n",
            "[[ 0.40465197 -0.14875916]\n",
            " [ 0.20017831  0.5240522 ]\n",
            " [-0.5184915   0.07348169]]\n",
            "\n",
            "Weights of bias after update: \n",
            "[ 0.00993361 -0.0099644 ]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert X and y to TensorFlow tensors\n",
        "X_tf = tf.convert_to_tensor(X.numpy(), dtype=tf.float32)\n",
        "y_tf = tf.convert_to_tensor(y.numpy(), dtype=tf.float32)\n",
        "\n",
        "no_of_epoch = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(no_of_epoch):  \n",
        "    print(f\"\\n\\n\\n\\nEpoch {epoch+1}:\")\n",
        "    \n",
        "    with tf.GradientTape() as tape:             \n",
        "        # Forward pass\n",
        "        outputs = model(X_tf)\n",
        "        loss = loss_fn(y_tf, outputs)\n",
        "\n",
        "        # Print loss for tracking\n",
        "        print(f\"\\nEpoch [{epoch+1}/{no_of_epoch}], Loss: {loss.numpy()}\")\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "    # Print gradients for each layer\n",
        "    for var, grad in zip(model.trainable_variables, gradients):\n",
        "        print(f\"\\nGradient of {var.name} after backward pass: \\n{grad.numpy()}\")\n",
        "\n",
        "    # Print weights before the update\n",
        "    for var in model.trainable_variables:\n",
        "        print(f\"\\nWeights of {var.name} before update: \\n{var.numpy()}\")\n",
        "\n",
        "    # Update weights\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # Print weights after the update\n",
        "    for var in model.trainable_variables:\n",
        "        print(f\"\\nWeights of {var.name} after update: \\n{var.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mini Batch gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Train Loss: 0.7076, Test Loss: 0.7007\n",
            "Epoch [2/20], Train Loss: 0.7066, Test Loss: 0.6989\n",
            "Epoch [3/20], Train Loss: 0.7054, Test Loss: 0.6975\n",
            "Epoch [4/20], Train Loss: 0.7041, Test Loss: 0.6963\n",
            "Epoch [5/20], Train Loss: 0.7031, Test Loss: 0.6951\n",
            "Epoch [6/20], Train Loss: 0.7019, Test Loss: 0.6939\n",
            "Epoch [7/20], Train Loss: 0.7011, Test Loss: 0.6926\n",
            "Epoch [8/20], Train Loss: 0.6997, Test Loss: 0.6914\n",
            "Epoch [9/20], Train Loss: 0.6990, Test Loss: 0.6903\n",
            "Epoch [10/20], Train Loss: 0.6982, Test Loss: 0.6891\n",
            "Epoch [11/20], Train Loss: 0.6970, Test Loss: 0.6881\n",
            "Epoch [12/20], Train Loss: 0.6960, Test Loss: 0.6872\n",
            "Epoch [13/20], Train Loss: 0.6953, Test Loss: 0.6862\n",
            "Epoch [14/20], Train Loss: 0.6943, Test Loss: 0.6852\n",
            "Epoch [15/20], Train Loss: 0.6938, Test Loss: 0.6840\n",
            "Epoch [16/20], Train Loss: 0.6927, Test Loss: 0.6830\n",
            "Epoch [17/20], Train Loss: 0.6920, Test Loss: 0.6821\n",
            "Epoch [18/20], Train Loss: 0.6913, Test Loss: 0.6812\n",
            "Epoch [19/20], Train Loss: 0.6903, Test Loss: 0.6804\n",
            "Epoch [20/20], Train Loss: 0.6895, Test Loss: 0.6794\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Sample dataset\n",
        "X = np.array([[1.0, 0.5],\n",
        "              [0.9, 0.7],\n",
        "              [0.4, 0.6],\n",
        "              [0.3, 0.4],\n",
        "              [1.1, 0.8],\n",
        "              [0.6, 0.9]], dtype=np.float32)\n",
        "\n",
        "y = np.array([[1, 1], [1, 1], [0, 1], [0, 0], [1, 1], [1, 1]], dtype=np.float32)\n",
        "\n",
        "# Scaling the data\n",
        "standard_scaler = StandardScaler()\n",
        "data_standardized = standard_scaler.fit_transform(X)\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "data_normalized = min_max_scaler.fit_transform(data_standardized)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(data_normalized, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.float32)\n",
        "\n",
        "# Splitting into training and testing sets (80:20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create TensorFlow Dataset for mini-batch gradient descent\n",
        "batch_size = 1  # Adjust batch size here\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size).shuffle(len(X_train))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
        "\n",
        "# Define Neural Network\n",
        "class SimpleNN(keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = layers.Dense(3, activation='relu')\n",
        "        self.fc2 = layers.Dense(2, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.fc1(inputs)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate model, loss function, and optimizer\n",
        "model = SimpleNN()\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Training loop with Mini-Batch Gradient Descent\n",
        "no_of_epoch = 20\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "for epoch in range(no_of_epoch):\n",
        "    # Training phase\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs_train = model(batch_X)\n",
        "            train_loss = loss_fn(batch_y, outputs_train)\n",
        "        \n",
        "        # Compute gradients and update weights\n",
        "        gradients = tape.gradient(train_loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        \n",
        "        running_loss += train_loss.numpy()\n",
        "    \n",
        "    # Store average training loss\n",
        "    avg_train_loss = running_loss / len(train_dataset)\n",
        "    train_loss_history.append(avg_train_loss)\n",
        "\n",
        "    # Testing phase (without gradient calculation)\n",
        "    test_loss = 0.0\n",
        "    for batch_X, batch_y in test_dataset:\n",
        "        outputs_test = model(batch_X)\n",
        "        batch_test_loss = loss_fn(batch_y, outputs_test)\n",
        "        test_loss += batch_test_loss.numpy()\n",
        "\n",
        "    avg_test_loss = test_loss / len(test_dataset)\n",
        "    test_loss_history.append(avg_test_loss)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch [{epoch + 1}/{no_of_epoch}], \"\n",
        "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
        "          f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "# Plot Training and Testing Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, no_of_epoch + 1), train_loss_history, label='Training Loss', color='blue', marker='o')\n",
        "plt.plot(range(1, no_of_epoch + 1), test_loss_history, label='Testing Loss', color='red', marker='x')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs. Testing Loss (Mini-Batch GD)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
